{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install websocket\n",
    "!pip install websocket-client\n",
    "!pip install supabase tiktoken openai langchain\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Perplexity import Perplexity\n",
    "from supabase import create_client, Client\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HOSTNAME = os.environ.get(\"HOSTNAME\")\n",
    "PORT = os.environ.get(\"PORT\")\n",
    "PASSWORD = os.environ.get(\"PASSWORD\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "SUPABASE_URL = os.environ.get(\"SUPABASE_URL\")\n",
    "SUPABASE_SERVICE_KEY = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "client: Client = create_client(os.environ[\"SUPABASE_URL\"], os.environ[\"SUPABASE_SERVICE_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Architecture', 'Architectural Studies', 'Undergraduate Business', 'Bioengineering', 'Chemical And Biomolecular Engineering', 'Civil and Environmental Engineering', 'Computational and Applied Mathematics and Operations Research', 'Computer Science', 'Electrical and Computer Engineering', 'Materials Science and Nanoengineering', 'Mechanical Engineering', 'Statistics', 'Ancient Mediterranean Civilizations', 'Art History', 'Asian Studies', 'Classical Studies', 'English', 'European Studies', 'French Studies', 'German Studies', 'History', 'Latin American and Latinx Studies', 'Medieval and Early Modern Studies', 'Philosophy', 'Religion', 'Spanish, Portuguese and Latin American Studies', 'Study of Women, Gender and Sexuality', 'Visual and Dramatic Arts', 'Bassoon Performance', 'Cello Performance', 'Clarinet Performance', 'Composition', 'Double Bass Performance', 'Flute Performance', 'Harp Performance', 'Horn Performance', 'Music', 'Music History', 'Music Theory', 'Oboe Performance', 'Organ Performance', 'Percussion Performance', 'Piano Performance', 'Trombone Performance', 'Trumpet Performance', 'Tuba Performance', 'Viola Performance', 'Violin Performance', 'Vocal Performance', 'Astronomy', 'Astrophysics', 'Biosciences', 'Chemical Physics', 'Chemistry', 'Earth, Environmental and Planetary Sciences', 'Ecology and Evolutionary Biology', 'Environmental Science', 'Kinesiology', 'Mathematics', 'Neuroscience', 'Physics And Astronomy', 'Anthropology', 'Cognitive Sciences', 'Economics', 'Linguistics', 'Managerial Economics and Organizational Sciences', 'Mathematical Economic Analysis', 'Political Science', 'Psychological Sciences', 'Social Policy Analysis', 'Sociology', 'Sport Management']\n"
     ]
    }
   ],
   "source": [
    "major_list = []\n",
    "\n",
    "file_path = \"./major_list.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            major_list.append(line)\n",
    "\n",
    "major_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2023-07-29 17:00:19,673:INFO - Websocket connected\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.49s/it]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "\n",
    "# academic\n",
    "# questions = [f'What academic resources are there for rice university students who major in {major}?' for major in major_list]\n",
    "# PHD\n",
    "# questions = [f'I am currently an undergrad at Rice major in {major}. I want to pursue PHD after graduation. What resouces are there at Rice to help me prepare and apply for PHD in {major}?' for major in major_list]\n",
    "# programs\n",
    "# questions = [f'What extra-curricular programs are there for Rice University students major in {major}?' for major in major_list]\n",
    "# career\n",
    "# questions = [f'What career resources are there for Rice University students major in {major}?' for major in major_list]\n",
    "\n",
    "# questions = ['What entrepreneurship programs and resources are there at Rice?']\n",
    "# questions = ['How and where to reach out Rice University Alumni networks?']\n",
    "# questions = ['Which rice alumnis from Rice are working on a startp?']\n",
    "# questions = ['What resources are there for Rice students for investment banking recruiting?']\n",
    "questions = []\n",
    "failed_questions = []\n",
    "question_answer_pair = []\n",
    "\n",
    "# Perplexity AI answers each question\n",
    "for question in tqdm(questions):\n",
    "    try:\n",
    "        perplexity = Perplexity()\n",
    "        response = perplexity.search(question)\n",
    "\n",
    "        answer = response.json_answer_text['answer']\n",
    "        citations = '\\n\\ncitations: \\n'\n",
    "        for web_result_idx in range(len(response.json_answer_text['web_results'])):\n",
    "            web_result = response.json_answer_text['web_results'][web_result_idx]\n",
    "            url = web_result['url']\n",
    "            citations += f'{[web_result_idx + 1]} {url} \\n'\n",
    "\n",
    "        answer += citations\n",
    "\n",
    "        answer = textwrap.dedent(answer).strip().replace('\\n', ' ')\n",
    "        question_answer_pair.append({'question': question, 'answer': answer})\n",
    "    except Exception as e:\n",
    "        print(f\"Error {str(e)} occurred while processing the question: {question}\")\n",
    "        failed_questions.append(question)\n",
    "        continue\n",
    "\n",
    "# Save the question answer pair in a local CSV\n",
    "with open(\"./faq.csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    fieldnames = ['question', 'answer']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(question_answer_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02e71a1e-489c-49e7-bc43-31c60016d024',\n",
       " '7d9a6d0a-dd7e-4967-8368-925105e2cff9',\n",
       " '62fcb79f-e77b-4dae-b316-389b72e6e44c',\n",
       " 'c0fcdeac-bdcd-4333-8f1c-9a247fbdde98',\n",
       " 'bc1463f4-d700-4d01-803d-0dcefd51411a',\n",
       " '1d5661d3-e0e3-484c-8175-91c3a9bd4f76',\n",
       " '4aec2d10-e29b-4216-bec9-00a0d7d68e55',\n",
       " 'fd9232d7-e84a-4673-b92d-89b56919b1ab',\n",
       " 'f834bd2d-39bd-4f45-ade6-9fae72067ff1',\n",
       " '392d8e2d-fe79-4d0a-b25d-ac9773735599',\n",
       " '4eb2b276-0479-48bd-baa9-afbb911d9baa',\n",
       " 'bd965405-046c-419f-bb18-e96aefd64614',\n",
       " 'ab98ea07-7cee-4a46-b504-3d33d5d9aef1',\n",
       " 'b19ac410-b861-42a5-b8fa-de52ae45b2c3',\n",
       " 'f86521fd-b43f-455e-a70f-5cf2530faf75',\n",
       " 'c1c7298b-2ed0-41e2-9d01-b50ca6fe2e95',\n",
       " 'c4d2286b-882e-4ada-8fd1-c91e6f09db6e',\n",
       " 'e4ac6eaa-e02a-4169-bd81-28338c7faa02',\n",
       " 'ef3ac22c-cc82-49e1-bee6-a462d2e7c1eb',\n",
       " 'd8c8fd7a-2c04-425c-a75f-b1f9566f3dce',\n",
       " 'a5969bf2-2239-44ea-9f6c-206a684aff3c',\n",
       " 'e30a433c-0604-4ace-b264-87ee20660ff7',\n",
       " '2ccd4915-835d-4a63-900b-27cad94e3476',\n",
       " '5e3c056b-9a69-40ce-9bc4-d822c64d2dfc',\n",
       " 'ca22b2e8-5c99-4eb3-ad72-cc80627d6b75',\n",
       " '54fc29df-f50a-4b59-8e71-1aa49d3ea7e9',\n",
       " 'e8a3ef25-f963-48fe-8a8b-469c3334a653',\n",
       " '7ff18606-0135-435c-b17f-eb2ec705704e',\n",
       " 'd1aa5aec-2d66-433e-9f30-bcf53be241e5',\n",
       " 'ad202c5c-8650-489d-8e8a-e82e34901a9c',\n",
       " '93e2bf0c-0b2a-4179-a884-bce243340448',\n",
       " 'c95686b6-52ec-4727-a091-ac90f9937368',\n",
       " '811a169f-95cb-478a-98ee-fbfc42680ab0',\n",
       " '508529f5-fc1e-4103-8490-7adab93da908',\n",
       " '622afb53-bcef-4154-8b26-b855ddace1fc',\n",
       " 'a3f82d12-2cd7-4781-a1ee-abaa19a91607',\n",
       " '9e1ddfad-5c3c-425c-a1b5-7dfaa4e10b92',\n",
       " '75428336-ea27-458a-898a-86d7c899fd4c',\n",
       " '2a3dfcf3-d99f-492f-a601-6cebe541bf0c',\n",
       " 'f35edad1-d714-496e-9b67-4914826c9224',\n",
       " 'd429a61f-0931-4c02-9cf8-ee9f02cf4591',\n",
       " '65b36a77-e952-4d6d-af61-6654e97ad293',\n",
       " '0b82b7fc-615e-4894-8cf7-6ebe4dae7ccc',\n",
       " '3d594057-a1a9-4fce-939f-35ed2d0197b5',\n",
       " 'b0b77afe-c33b-4dc8-8ecb-72c76d6906d8',\n",
       " 'b9fe042b-e292-4dfc-a6e1-96386d666c99',\n",
       " '522ec23d-32e5-4e1a-a99c-554d24dc6db9',\n",
       " '66590a41-4204-432e-8268-be384c51103d',\n",
       " '4f7e91af-dfcc-4a8d-bc7f-384c4c82cbcf',\n",
       " '79103179-4be1-42c8-895e-1284742b9e19',\n",
       " '577303d1-9bae-46d1-81a8-6a9b38a6526e',\n",
       " '3174fab6-b747-4af6-891b-3bac38ac7c83',\n",
       " '584230a9-14ca-4181-9191-a14470eda3f2',\n",
       " 'ad733070-618c-4588-b939-9ce61b234c6c',\n",
       " 'e01a099d-54a6-4e54-9120-abbaa77e8fec',\n",
       " '734d4c25-e8aa-4592-a6b0-1fe6a2f6ec2e',\n",
       " '1fad5975-ba82-4f90-8385-e2b73d0aa865',\n",
       " '9f8d84df-1ece-4011-902f-5b540896ab0d',\n",
       " '777ff444-232e-4e74-977b-156e40e3c7a8',\n",
       " '93442097-22c5-44b0-ba5a-1b5719dc2016',\n",
       " '685a2591-6361-4228-9883-3882674bba7d',\n",
       " '9cd04c34-660d-4e9d-a77f-07c72711f282',\n",
       " '4824b5e4-c784-4e50-b11f-798ad409235e',\n",
       " 'a020317d-e304-4602-bb9c-88fe3719b501',\n",
       " 'cb4bfe6f-e115-4709-afe3-5f1ddfeaf8f0',\n",
       " '5aeb8355-1c70-4890-bdfd-006dc4ac9aa7',\n",
       " 'faf8c60e-0fb1-41a8-b5a0-12a6c6689610',\n",
       " 'd3b3a3cf-d4c3-4c29-8a34-598e2bd7e41e',\n",
       " '1ff4d531-c3a7-415d-8c7f-9a51e2988f75',\n",
       " '43d058c3-23e1-4b76-b876-ad22b567ec58',\n",
       " 'a81adf6c-486e-41a9-93f9-80757e5f8198',\n",
       " '6005cd1b-ff8e-47c6-8c03-86422c2c3d2e']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"./faq.csv\",  source_column=\"question\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "vector_store = SupabaseVectorStore(client=client,\n",
    "                                   embedding=embeddings,\n",
    "                                   table_name='faq')\n",
    "\n",
    "vector_store.add_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-learn based on user chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "def get_all_failed_queries():\n",
    "    def connect_reddis():\n",
    "        return redis.Redis(\n",
    "            host=HOSTNAME,\n",
    "            port=PORT, \n",
    "            password=PASSWORD,\n",
    "            ssl=True,\n",
    "            decode_responses=True\n",
    "        )\n",
    "\n",
    "    r = connect_reddis()\n",
    "\n",
    "    # Get all chat keys by pattern\n",
    "    all_keys = r.keys('chat:*')\n",
    "\n",
    "    # Get all failed queries\n",
    "    all_fail_query = []\n",
    "\n",
    "    for hash_key in all_keys:\n",
    "        hash_data = r.hgetall(hash_key)\n",
    "\n",
    "        messages = json.loads(hash_data['messages'])\n",
    "        for idx in range(len(messages)):\n",
    "            message = messages[idx]\n",
    "            role = message['role']\n",
    "            content = message['content']\n",
    "            if role == 'assistant' and 'sorry' in content.lower():\n",
    "                if idx - 1 >= 0:\n",
    "                    prev_message = messages[idx - 1]\n",
    "                    if prev_message['role'] == 'user':\n",
    "                        all_fail_query.append(prev_message['content'])\n",
    "    \n",
    "    return all_fail_query\n",
    "\n",
    "\n",
    "def perplexity_solve_with_rice_context(question):\n",
    "    try:\n",
    "        if \"rice\" not in question.lower():\n",
    "            question = 'At Rice university: ' + question\n",
    "\n",
    "        perplexity = Perplexity()\n",
    "        response = perplexity.search(question)\n",
    "\n",
    "        answer = response.json_answer_text['answer']\n",
    "        citations = '\\n\\ncitations: \\n'\n",
    "        for web_result_idx in range(len(response.json_answer_text['web_results'])):\n",
    "            web_result = response.json_answer_text['web_results'][web_result_idx]\n",
    "            url = web_result['url']\n",
    "            citations += f'{[web_result_idx + 1]} {url} \\n'\n",
    "\n",
    "        answer += citations\n",
    "\n",
    "        answer = textwrap.dedent(answer).strip().replace('\\n', ' ')\n",
    "\n",
    "        return question, answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error {str(e)} occurred while processing the question: {question}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
